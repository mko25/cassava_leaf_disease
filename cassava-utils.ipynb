{"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport json\nimport random\n\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom torchvision import models\n\n\ndef display_images(img_ids, annotations_df, img_rootdir, label2name_json, rows=3, cols=3):\n    \"\"\"  \n    Displays random images in a grid of (rows)*(cols) with their labels\n    \n    Args:\n        img_ids (list): A list of the IDs of the images (= the file name of the images)\n        annotations_df (pandas.DataFrame): Contains the img_ids in first column\n            and the associated annotation in the second column\n        img_rootdir (string): Root directory of the image files\n        label2name_json (json): The mapping between each disease code and the real disease name.\n        rows (int): Number of rows of the image grid (default=3)\n        cols (int): Number of columns of the image grid (default=3)\n    \"\"\"\n    with open(label2name_json, \"r\") as file:\n        data = file.read()\n    label2name = json.loads(data)\n        \n    random.shuffle(img_ids)\n    img_ids = img_ids[:rows*cols]\n    \n    fig, axs = plt.subplots(rows, cols, figsize=(20,20))\n    for i, img_id in enumerate(img_ids):\n        img_path = os.path.join(img_rootdir, img_id)\n        img = Image.open(img_path)\n        label = annotations_df.loc[annotations_df.image_id==img_id].label.item()\n        label_name = label2name[str(label)]\n        axs.ravel()[i].imshow(img)\n        axs.ravel()[i].set_title(\" \".join([str(label),label_name]))\n        axs.ravel()[i].set_xlabel(img_id)\n        axs.ravel()[i].get_yaxis().set_visible(False)\n    plt.show()\n\n    \nclass SimpleNet(nn.Module):\n    def __init__(self):\n        super(SimpleNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 53 * 53, 1000)\n        self.fc2 = nn.Linear(1000, 256)\n        self.fc3 = nn.Linear(256, 5)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 53 * 53)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    \ndef create_model(device, pretrained=True):\n    \"\"\"  \n    Creates a Resnet50 model with all layers (except fc layer) frozen,\n        for 5-class classification\n    \n    Args:\n        device (string): Device, where to put the model\n        pretrained (boolean): If the model should be loaded pretrained on ImageNet\n            (default=True)\n\n    Returns:\n        torch.nn.Module\n    \"\"\"\n    model = models.resnet50(pretrained=pretrained)\n    \n    # freeze all params\n    for param in model.parameters():\n        param.requires_grad = False\n    \n    # replace last layer\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(num_ftrs, 5)\n    \n    return model.to(device)\n\ndef create_model_layer4(device, pretrained=True): \n    \"\"\"  \n    Creates a Resnet50 model with all layers (except layer4 and fc layer) frozen,\n        for 5-class classification\n    \n    Args:\n        device (string): Device, where to put the model\n        pretrained (boolean): If the model should be loaded pretrained on ImageNet\n            (default=True)\n\n    Returns:\n        torch.nn.Module\n    \"\"\"\n    model = models.resnet50(pretrained=pretrained)   \n    \n    # freeze all params and unfreeze params of layer4\n    for param in model.parameters():\n        param.requires_grad = False\n    for param in model.layer4.parameters():\n        param.requires_grad = True\n    \n    #replace last layer\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(num_ftrs, 5)\n\n    return model.to(device)\n    \n\nclass CassavaDataset(Dataset):\n    def __init__(self, annotations_df, root_dir, transforms=None, albums=None):\n        \"\"\"\n        Args:\n            annotations_df (pandas.DataFrame): Contains the img_ids in first \n                column and the associated annotation in the second column\n            root_dir (string): Root directory of the image files\n            transforms (callable, optional): Optional torchvision.transforms \n                to be applied on a sample\n            albums (callable, optional): Optional albumentations to be applied \n                on a sample\n        \"\"\"\n        self.annotations_df = annotations_df\n        self.img_ids = np.asarray(self.annotations_df.iloc[:,0])\n        self.labels = np.asarray(self.annotations_df.iloc[:,1])\n        self.root_dir = root_dir\n        self.transforms = transforms\n        self.albums = albums\n        \n    def __getitem__(self, idx):\n        img_id = self.img_ids[idx]\n        img_filepath = os.path.join(self.root_dir, str(img_id))\n        img = Image.open(img_filepath)\n        \n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n        \n        if self.transforms is not None: # works for torchvision.transforms\n            img = self.transforms(img)\n        \n        if self.albums is not None: # works for albumentations\n            img = np.array(img)\n            img = self.albums(image=img)[\"image\"]\n            \n        return (img, label)\n    \n    def __len__(self):\n        return len(self.img_ids)\n    \n\nclass CassavaTestDataset(Dataset):\n    def __init__(self, img_ids, root_dir, transforms=None, albums=None):\n        \"\"\"\n        Args:\n            img_ids (list): A list of the IDs of the images (= the file name of the images)\n            root_dir (string): Root directory of the image files\n            transforms (callable, optional): Optional torchvision.transforms \n                to be applied on a sample\n            albums (callable, optional): Optional albumentations to be applied \n                on a sample\n        \"\"\"\n        self.root_dir = root_dir\n        self.img_ids = img_ids\n        self.transforms = transforms\n        self.albums = albums\n        \n    def __getitem__(self, idx):\n        img_id = self.img_ids[idx]\n        img_filepath = os.path.join(self.root_dir, str(img_id))\n        img = Image.open(img_filepath)\n        \n        if self.transforms is not None: # works for torchvision.transforms\n            img = self.transforms(img)\n        \n        if self.albums is not None: # works for albumentations\n            img = np.array(img)\n            img = self.albums(image=img)[\"image\"]\n            \n        return (img_id, img)\n    \n    def __len__(self):\n        return len(self.img_ids)\n\n    \ndef check_dataloaders(dataloaders, dataset_type=\"train\", index=0, std=1, mean=0):\n    \"\"\"  \n    Grabs one element of a dataloader and...\n        ...for CassavaDataset-dataloader: prints image and its annotation\n        ...for CassavaTestDataset-dataloader: prints image and its ID\n    \n    Args:\n        dataloaders (dictionary): Contains DataLoader obect(s) named \"train\",\n            \"val\" or \"test\"\n        dataset_type (string): Type of the dataloader (\"train\",\n            \"val\" or \"test\") (default=\"train\")\n        index (int): Defines which index of the dataloader should be plotted\n            (requirement: index < batch size)\n        std (float): Standard deviation chosen in image transform or albumentation\n            of the dataloader (default=1)\n        mean (float): Mean chosen in image transform or albumentation\n            of the dataloader (default=1)\n    \"\"\"\n    dataiter = iter(dataloaders[dataset_type])\n    if dataset_type == \"test\":\n        img_id, img = dataiter.next()\n    else:\n        img, label = dataiter.next()\n    \n    # get first image in the batch\n    im = img.squeeze().numpy()\n    # im is already of shape [Height x Width x Channel] if only one file in batch\n    # if only one image in batch: don't do next step\n    if len(dataloaders[dataset_type]) > 1: im = im[index,:,:,:]  \n    \n    # permute to [Channel x Height x Width]\n    im = im.transpose((1,2,0))\n    \n    # unnormalize (reverse normalization)\n    im = im * std\n    im = im + mean\n    im[im<0] = 0\n       \n    if dataset_type == \"test\":\n        print (\"ID:\", str(img_id[index]))\n    else:\n        print(\"Label:\", label[index])\n        \n    plt.imshow(im)\n    \n     \nclass Engine():\n    def __init__(self, model, optimizer, device):\n        \"\"\"\n        Args:\n            model (torch.nn.module): Prepared model for task\n            optimizer (torch.optim): Optimizer for task\n            device (string): Device, where the model is stored\n        \"\"\"\n        self.model = model\n        self.optimizer = optimizer\n        self.device = device\n    \n    @staticmethod\n    def loss_fn(outputs, targets):\n        return nn.CrossEntropyLoss()(outputs, targets)\n    \n    def train(self, dataloader):\n        \"\"\"\n        Trains the model for one epoch on train dataloader\n        \n        Args:\n            dataloader (torch.utils.data.DataLoader): Train dataloader created\n                with CassavaDataset\n                \n        Returns:\n            float: Training loss\n        \"\"\"\n        self.model.train()\n        running_loss = 0.0\n        datasize = 0\n        for inputs, targets in dataloader:\n            self.optimizer.zero_grad()\n            inputs = inputs.to(self.device, dtype=torch.float)\n            targets = targets.long().to(self.device)\n            outputs = self.model(inputs)\n            loss = self.loss_fn(outputs, targets)\n            loss.backward()\n            self.optimizer.step()\n            running_loss += loss.item()\n        return running_loss / len(dataloader)\n    \n    def evaluate(self, dataloader):\n        \"\"\"\n        Evaluates the model on validation dataloader\n        \n        Args:\n            dataloader (torch.utils.data.DataLoader): Validation dataloader\n            created with CassavaDataset\n                \n        Returns:\n            float: Training loss\n            float: Accuracy\n        \"\"\"\n        self.model.eval()\n        running_loss = 0.0\n        running_corrects = 0\n        dataset_size = 0\n        for inputs, targets in dataloader:\n            inputs = inputs.to(self.device, dtype=torch.float)\n            targets = targets.long().to(self.device)\n            outputs = self.model(inputs)\n            _, preds = torch.max(outputs.data, 1)\n            running_corrects += torch.sum(preds == targets.data)\n            loss = self.loss_fn(outputs, targets)\n            running_loss += loss.item()\n            dataset_size += inputs.size(0)\n        return running_loss / len(dataloader), running_corrects / dataset_size\n    \n    def predict(self, dataloader):\n        \"\"\"\n        Returns predictions by one model on validation or test dataloader\n        \n        Args:\n            dataloader (torch.utils.data.DataLoader): Validation or test dataloader\n            created with CassavaTestDataset\n                \n        Returns:\n            pandas.DataFrame: Dataframe with image IDs as first column and\n                predicted classes as second label\n        \"\"\"\n        self.model.eval()\n        inference_df = pd.DataFrame()\n        for img_id, inputs in dataloader:\n            inputs = inputs.to(self.device)\n            outputs = self.model(inputs)\n            _, preds = torch.max(outputs.data, 1)\n            iter_df = pd.DataFrame({\"image_id\": list(img_id), \"label\": preds.tolist()})\n            inference_df = inference_df.append(iter_df, ignore_index=True)\n        return inference_df\n    \n    def ensemble_predict(self, dataloader, models):\n        \"\"\"\n        Returns ensembled predictions by multiple models on validation or test dataloader\n        \n        Args:\n            dataloader (torch.utils.data.DataLoader): Validation or test dataloader\n            created with CassavaTestDataset\n            models (dictionary of torch.nn.module): Dictionary of multiple models\n                \n        Returns:\n            pandas.DataFrame: Dataframe with image IDs as first column and\n                predicted classes as second label\n        \"\"\"\n        model_keys = list(models.keys())\n        \n        inference_df = pd.DataFrame()\n        for img_id, img in dataloader:\n            inputs = img.to(self.device)\n            for count, key in enumerate(model_keys):\n                if count == 0:\n                    outputs = models[key](inputs).data\n                else:\n                    outputs += models[key](inputs).data\n            outputs /= len(models)\n            _, preds = torch.max(outputs, 1)\n            iter_df = pd.DataFrame({\"image_id\": list(img_id), \"label\": preds.tolist()})\n            inference_df = inference_df.append(iter_df, ignore_index=True)\n        return inference_df","metadata":{"collapsed":false,"_kg_hide-input":false},"execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}